{
    "ops": [
        {
            "id": "llama-4-maverick",
            "args": {
                "cmd": [
                    "bash -c 'python3 -m vllm.entrypoints.openai.api_server --model meta-llama/Llama-4-Maverick-17B-128E-Instruct --port 9000'"
                ],
                "gpu": true,
                "image": "vllm/vllm-openai:latest",
                "expose": 9000,
                "env": {
                    "HF_TOKEN": "<your_huggingface_token>"
                },
                "resources": [
                    {
                        "url": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct",
                        "type": "S3",
                        "target": "/models/llama-4-maverick",
                        "allowWrite": false
                    }
                ]
            },
            "type": "container/run"
        }
    ],
    "meta": {
        "trigger": "dashboard",
        "system_requirements": {
            "required_vram": 80
        }
    },
    "type": "container",
    "version": "0.1"
}