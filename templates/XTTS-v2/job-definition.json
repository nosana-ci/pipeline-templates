{
  "ops": [
    {
      "id": "xtts-v2",
      "args": {
        "cmd": [
          "/bin/sh",
          "-c",
          "pip install TTS && git clone https://github.com/coqui-ai/TTS.git && cd TTS && pip install -e . && pip install gradio && python -c \"import gradio as gr; from TTS.api import TTS; def tts_generate(text, language, ref_audio): tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2', gpu=True); output_path = 'output.wav'; tts.tts_to_file(text=text, file_path=output_path, speaker_wav=ref_audio, language=language); return output_path; demo = gr.Interface(fn=tts_generate, inputs=[gr.Textbox(label='Text to speak'), gr.Dropdown(choices=['en', 'es', 'fr', 'de', 'it', 'pt', 'pl', 'tr', 'ru', 'nl', 'cs', 'ar', 'zh-cn', 'ja', 'hu', 'ko', 'hi'], label='Language'), gr.Audio(type='filepath', label='Reference voice (6 seconds)')], outputs='audio', title='Coqui XTTS-v2 Voice Cloning'); demo.launch(server_name='0.0.0.0', server_port=7860)\" --host 0.0.0.0 --port 7860"
        ],
        "env": {
          "PYTHONUNBUFFERED": "1"
        },
        "gpu": true,
        "image": "pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime",
        "expose": 7860,
        "entrypoint": []
      },
      "type": "container/run"
    }
  ],
  "meta": {
    "trigger": "dashboard",
    "system_requirements": {
      "required_vram": 10
    }
  },
  "type": "container",
  "version": "0.1"
} 