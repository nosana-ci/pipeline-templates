# Gemma 3 LLM

## Description
This template runs Google's Gemma 3 LLM, providing a powerful chat and generation model through a Docker container using vLLM's OpenAI API server. It requires a GPU with at least 24GB of VRAM.
